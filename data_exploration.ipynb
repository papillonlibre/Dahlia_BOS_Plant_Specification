{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Specify the path to the folder containing JPG files\n",
    "folder_path = 'BTTAIxNYBG-train/BTTAIxNYBG-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uniqueID           classLabel  classID source             imageFile\n",
      "0         2   occluded-specimens        8      L  a1a8b48e8cb142b3.jpg\n",
      "1         3    microscope-slides        6      L  79599db2ac9092b6.jpg\n",
      "2         4  illustrations-color        2    BHL  c449696f2f0d0d92.jpg\n",
      "3         5  illustrations-color        2      P  80a8f4a393b4e08c.jpg\n",
      "4         6     animal-specimens        0     AK  041a1c6e73313638.jpg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "df = pd.read_csv('BTTAIxNYBG-train.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify that it was loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of DataFrame:\", df.shape)\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "if duplicate_rows.empty:\n",
    "    print(\"No duplicate rows.\")\n",
    "else:\n",
    "    print(\"Duplicate rows:\\n\", duplicate_rows)\n",
    "print(\"Summary statistics for numerical columns:\\n\", df.describe())\n",
    "categorical_columns = ['classLabel', 'source']\n",
    "for column in categorical_columns:\n",
    "    print(\"Unique values in\", column, \":\", df[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_columns = ['classLabel', 'source']\n",
    "\n",
    "# Plot pie charts for each categorical column\n",
    "for column in categorical_columns:\n",
    "    # Count the frequency of each category\n",
    "    category_counts = df[column].value_counts()\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(\"Pie chart of \" + column)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Check if TensorFlow is using GPU acceleration\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Check which device TensorFlow is currently using\n",
    "print(\"Device:\", tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame containing image information\n",
    "# Assuming you have a directory 'images' containing the actual images\n",
    "training_proportion = 0.01\n",
    "num_images_for_training = int(len(df) * training_proportion)\n",
    "training_filenames = random.sample(df['imageFile'].tolist(), num_images_for_training)\n",
    "print(\"Number of files for training: \" + str(len(training_filenames)))\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Load images and preprocess them\n",
    "image_data = []\n",
    "y_data = []\n",
    "for i, filename in enumerate(training_filenames):\n",
    "    image = load_img('BTTAIxNYBG-train/BTTAIxNYBG-train/' + filename, target_size=(224, 224))  # Assuming resizing to 224x224\n",
    "    image = img_to_array(image)\n",
    "    image_data.append(image)\n",
    "    y_data.append(df[df['imageFile'] == filename]['classID'].values[0])  # Collect class ID for the current image\n",
    "     # Print statement to show progress\n",
    "    print(\"Processed {} out of {} images for training.\".format(i+1, len(training_filenames)))\n",
    "X = np.array(image_data)\n",
    "X = X / 255.0  # Normalization\n",
    "\n",
    "# Convert class labels to categorical format\n",
    "y = to_categorical(y_data)\n",
    "\n",
    "print(\"Image preprocessing completed\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Splitting Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"The data has been split\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name: conv2d, Layer: <keras.layers.convolutional.conv2d.Conv2D object at 0x00000215BAEDBD00>\n",
      "Layer name: max_pooling2d, Layer: <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000215BAEDB850>\n",
      "Layer name: conv2d_1, Layer: <keras.layers.convolutional.conv2d.Conv2D object at 0x000002158610D370>\n",
      "Layer name: max_pooling2d_1, Layer: <keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x00000215E4253880>\n",
      "Layer name: flatten, Layer: <keras.layers.reshaping.flatten.Flatten object at 0x000002158610D190>\n",
      "Layer name: dense, Layer: <keras.layers.core.dense.Dense object at 0x000002158610DB20>\n",
      "Layer name: dense_1, Layer: <keras.layers.core.dense.Dense object at 0x000002158610DBE0>\n",
      "Model architecture chosen\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Choosing a Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # Assuming 10 classes\n",
    "])\n",
    "for layer in model.layers:\n",
    "    print(f\"Layer name: {layer.name}, Layer: {layer}\")\n",
    "print(\"Model architecture chosen\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 111, 111, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 186624)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                11944000  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,964,042\n",
      "Trainable params: 11,964,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Only run this if the Tensorflow Model needs to be trained and can not be loaded from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Training\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=2, validation_data=(X_test, y_test),callbacks=[cp_callback] )\n",
    "model.save(\"my_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Model Evaluation\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model in from CheckPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x215bb1026d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the previously saved weights\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Test Set Evaluation and Writing to File\n",
    "\n",
    "Need to evaluate to upload to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30690\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 1: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 50s 155ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 2: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 38s 144ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 3: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 37s 141ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 4: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 37s 141ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 5: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 37s 144ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 6: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 37s 141ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 7: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 35s 134ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 8: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 40s 154ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 9: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 36s 137ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 10: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 36s 137ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 11: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 36s 138ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 12: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 36s 140ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 13: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 36s 139ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 14: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 36s 138ms/step\n",
      "Temp shape of data_subset: 2046\n",
      "Processed subset 15: 2046\n",
      "Length of image data:  2046\n",
      "Size of test_dataset: 256\n",
      "256/256 [==============================] - 36s 138ms/step\n",
      "Final shape of X_test: 30690\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "df_2 = pd.read_csv('BTTAIxNYBG-test.csv')\n",
    "testing_filenames = df_2['imageFile'].tolist()\n",
    "unique_IDs = df_2['uniqueID'].tolist()\n",
    "total_samples = len(testing_filenames)\n",
    "subset_proportion = 15\n",
    "subset_size = total_samples // subset_proportion\n",
    "print(len(testing_filenames))\n",
    "batch_size = 8\n",
    "my_file_endings =\"abcdefghijklmnop\"\n",
    "\n",
    "for i in range(0, subset_proportion):\n",
    "    start_idx = i * subset_size\n",
    "    end_idx = (i+1) * subset_size\n",
    "    data_subset = testing_filenames[start_idx:end_idx]\n",
    "    print(\"Temp shape of data_subset:\" , len(data_subset))\n",
    "    print(f\"Processed subset {i+1}: {len(data_subset)}\")\n",
    "    image_data = []\n",
    "    for j, filename in enumerate(data_subset):\n",
    "        # print(f\"Shape of image {j + 1}: {image.shape}\")\n",
    "        image = load_img('BTTAIxNYBG-test/BTTAIxNYBG-test/' + filename, target_size=(224, 224))  # Assuming resizing to 224x224\n",
    "        image = img_to_array(image)\n",
    "        image_data.append(image)\n",
    "        # print(\"Processed {} out of {} images for testing.\".format(i+1, subset_size))\n",
    "    print(\"Length of image data: \", len(image_data))\n",
    "    image_data = np.array(image_data)\n",
    "    # image_data = np.expand_dims(image_data, axis=0)  # Add batch dimension\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(image_data)\n",
    "    # test_dataset = tf.data.Dataset.from_tensor_slices(img_to_array(load_img('BTTAIxNYBG-test/BTTAIxNYBG-test/65f1c96cf4e064b8.jpg', target_size=(224, 224))))\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    print(\"Size of test_dataset:\", tf.data.experimental.cardinality(test_dataset).numpy())\n",
    "    predictions = model.predict(test_dataset)\n",
    "    class_labels = tf.argmax(predictions, axis=1).numpy().astype(int)\n",
    "    combined_data = zip(unique_IDs[start_idx:end_idx], class_labels)\n",
    "    # save array into csv file \n",
    "    # np.savetxt(f\"data_{i+1}.csv\", combined_data, delimiter=\",\", fmt='%i')\n",
    "    with open(f\"data_{my_file_endings[i]}.csv\", 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerows(combined_data)\n",
    "print(\"Final shape of X_test:\" , len(testing_filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize counters\n",
    "# grayscale_count = 0\n",
    "# colorful_count = 0\n",
    "\n",
    "# # List all files in the folder\n",
    "# files = os.listdir(folder_path)\n",
    "\n",
    "# # Iterate over each file\n",
    "# for file in files:\n",
    "#     # Check if the file is a JPG file\n",
    "#     if file.endswith('.jpg'):\n",
    "#         # Construct the full path to the image file\n",
    "#         image_path = os.path.join(folder_path, file)\n",
    "        \n",
    "#         # Read the image using OpenCV\n",
    "#         image = cv2.imread(image_path)\n",
    "        \n",
    "#         # Check if the image was successfully read\n",
    "#         if image is not None:\n",
    "#             # Check if the image is grayscale\n",
    "#             if len(image.shape) < 3:\n",
    "#                 grayscale_count += 1\n",
    "#             else:\n",
    "#                 colorful_count += 1\n",
    "                \n",
    "#         else:\n",
    "#             print(f\"Error reading image '{file}'\")\n",
    "\n",
    "# # Output the results\n",
    "# print(\"Analysis Results:\")\n",
    "# print(f\"Total images: {len(files)}\")\n",
    "# print(f\"Grayscale images: {grayscale_count}\")\n",
    "# print(f\"Colorful images: {colorful_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
